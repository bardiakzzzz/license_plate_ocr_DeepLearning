{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_ocr.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "1dxcrEFNgIiW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from os.path import join\n",
        "import json\n",
        "import random\n",
        "import itertools\n",
        "import re\n",
        "import datetime\n",
        "import editdistance\n",
        "import numpy as np\n",
        "from scipy import ndimage\n",
        "import pylab\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "from keras import backend as K\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.layers import Input, Dense, Activation\n",
        "from keras.layers import Reshape, Lambda\n",
        "from keras.layers.merge import add, concatenate\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers.recurrent import GRU\n",
        "from keras.optimizers import SGD\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.preprocessing import image\n",
        "import keras.callbacks\n",
        "import cv2\n",
        "import zipfile\n",
        "!pip install sh\n",
        "from sh import cd\n",
        "from collections import Counter\n",
        "sess = tf.Session()\n",
        "K.set_session(sess)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ripjPpQ15F20",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Get Dataset from Git**"
      ]
    },
    {
      "metadata": {
        "id": "axLL5zvgjczu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/bardiakzzzz/license_plate_ocr_Dp.git\n",
        "cd('license_plate_ocr_Dp')\n",
        "zip_ref = zipfile.ZipFile('anpr_ocr-1790.zip', 'r')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "19kaMyRigIie",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Get alphabet"
      ]
    },
    {
      "metadata": {
        "id": "CU9w-em3gIif",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_counter(dirpath):\n",
        "    dirname = os.path.basename(dirpath)\n",
        "    ann_dirpath = join(dirpath, 'ann')\n",
        "    letters = ''\n",
        "    lens = []\n",
        "    for filename in os.listdir(ann_dirpath):\n",
        "        json_filepath = join(ann_dirpath, filename)\n",
        "        description = json.load(open(json_filepath, 'r'))['description']\n",
        "        lens.append(len(description))\n",
        "        letters += description\n",
        "    print('Max plate length in \"%s\":' % dirname, max(Counter(lens).keys()))\n",
        "    return Counter(letters)\n",
        "c_val = get_counter('./val/anpr_ocr/train/')\n",
        "c_train = get_counter('./train/anpr_ocr/train/')\n",
        "letters_train = set(c_train.keys())\n",
        "letters_val = set(c_val.keys())\n",
        "if letters_train == letters_val:\n",
        "    print('Letters in train and val do match')\n",
        "else:\n",
        "    raise Exception()\n",
        "letters = sorted(list(letters_train))\n",
        "print('Letters:', ' '.join(letters))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HT5C6gCVgIil",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Input data generator"
      ]
    },
    {
      "metadata": {
        "id": "B1KfbwrmgIil",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def labels_to_text(labels):\n",
        "    return ''.join(list(map(lambda x: letters[int(x)], labels)))\n",
        "\n",
        "def text_to_labels(text):\n",
        "    return list(map(lambda x: letters.index(x), text))\n",
        "\n",
        "def is_valid_str(s):\n",
        "    for ch in s:\n",
        "        if not ch in letters:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "class TextImageGenerator:\n",
        "    \n",
        "    def __init__(self,dirpath,img_w, img_h,batch_size,downsample_factor,max_text_len=8):        \n",
        "        self.img_h = img_h\n",
        "        self.img_w = img_w\n",
        "        self.batch_size = batch_size\n",
        "        self.max_text_len = max_text_len\n",
        "        self.downsample_factor = downsample_factor        \n",
        "        img_dirpath = join(dirpath, 'img')\n",
        "        ann_dirpath = join(dirpath, 'ann')\n",
        "        self.samples = []\n",
        "        for filename in os.listdir(img_dirpath):\n",
        "            name, ext = os.path.splitext(filename)\n",
        "            if ext == '.png':\n",
        "                img_filepath = join(img_dirpath, filename)\n",
        "                json_filepath = join(ann_dirpath, name + '.json')\n",
        "                description = json.load(open(json_filepath, 'r'))['description']\n",
        "                if is_valid_str(description):\n",
        "                    self.samples.append([img_filepath, description])        \n",
        "        self.n = len(self.samples)\n",
        "        self.indexes = list(range(self.n))\n",
        "        self.cur_index = 0\n",
        "        \n",
        "    def build_data(self):\n",
        "        self.imgs = np.zeros((self.n, self.img_h, self.img_w))\n",
        "        self.texts = []\n",
        "        for i, (img_filepath, text) in enumerate(self.samples):\n",
        "            img = cv2.imread(img_filepath)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            img = cv2.resize(img, (self.img_w, self.img_h))\n",
        "            img = img.astype(np.float32)\n",
        "            img /= 255\n",
        "            self.imgs[i, :, :] = img\n",
        "            self.texts.append(text)\n",
        "        \n",
        "    def get_output_size(self):\n",
        "        return len(letters) + 1\n",
        "    \n",
        "    def next_sample(self):\n",
        "        self.cur_index += 1\n",
        "        if self.cur_index >= self.n:\n",
        "            self.cur_index = 0\n",
        "            random.shuffle(self.indexes)\n",
        "        return self.imgs[self.indexes[self.cur_index]], self.texts[self.indexes[self.cur_index]]\n",
        "    \n",
        "    def next_batch(self):\n",
        "        while True:\n",
        "            if K.image_data_format() == 'channels_first':\n",
        "                X_data = np.ones([self.batch_size, 1, self.img_w, self.img_h])\n",
        "            else:\n",
        "                X_data = np.ones([self.batch_size, self.img_w, self.img_h, 1])\n",
        "            Y_data = np.ones([self.batch_size, self.max_text_len])\n",
        "            input_length = np.ones((self.batch_size, 1)) * (self.img_w // self.downsample_factor - 2)\n",
        "            label_length = np.zeros((self.batch_size, 1))\n",
        "            source_str = []                                   \n",
        "            for i in range(self.batch_size):\n",
        "                img, text = self.next_sample()\n",
        "                img = img.T\n",
        "                if K.image_data_format() == 'channels_first':\n",
        "                    img = np.expand_dims(img, 0)\n",
        "                else:\n",
        "                    img = np.expand_dims(img, -1)\n",
        "                X_data[i] = img\n",
        "                Y_data[i] = text_to_labels(text)\n",
        "                source_str.append(text)\n",
        "                label_length[i] = len(text)\n",
        "                \n",
        "            inputs = {\n",
        "                'the_input': X_data,\n",
        "                'the_labels': Y_data,\n",
        "                'input_length': input_length,\n",
        "                'label_length': label_length\n",
        "            }\n",
        "            outputs = {'ctc': np.zeros([self.batch_size])}\n",
        "            yield (inputs, outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6uD67Yea-ey8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Get **Sample**"
      ]
    },
    {
      "metadata": {
        "id": "fLwq-tQ5gIiq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tiger = TextImageGenerator('./val/anpr_ocr/train/', 128, 64, 8, 4)\n",
        "tiger.build_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BMU5pNaXgIiy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for inp, out in tiger.next_batch():\n",
        "    print('Text generator output (data which will be fed into the neutral network):')\n",
        "    print('1) the_input (image)')\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        img = inp['the_input'][0, 0, :, :]\n",
        "    else:\n",
        "        img = inp['the_input'][0, :, :, 0]\n",
        "    \n",
        "    plt.imshow(img.T, cmap='gray')\n",
        "    plt.show()\n",
        "    print('2) the_labels (plate number): %s is encoded as %s' % \n",
        "          (labels_to_text(inp['the_labels'][0]), list(map(int, inp['the_labels'][0]))))\n",
        "    print('3) input_length (width of image that is fed to the loss function): %d == %d / 4 - 2' % \n",
        "          (inp['input_length'][0], tiger.img_w))\n",
        "    print('4) label_length (length of plate number): %d' % inp['label_length'][0])\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d7JpJJpBgIi3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Loss and train functions, network architecture"
      ]
    },
    {
      "metadata": {
        "id": "ajIhvIEcgIi4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def ctc_lambda_func(args):\n",
        "    y_pred, labels, input_length, label_length = args\n",
        "    y_pred = y_pred[:, 2:, :]\n",
        "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
        "\n",
        "def train(load=False):\n",
        "    img_w = 128\n",
        "    img_h = 64\n",
        "    conv_filters = 16\n",
        "    kernel_size = (3, 3)\n",
        "    pool_size = 2\n",
        "    time_dense_size = 32\n",
        "   \n",
        "\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        input_shape = (1, img_w, img_h)\n",
        "    else:\n",
        "        input_shape = (img_w, img_h, 1)\n",
        "        \n",
        "    batch_size = 32\n",
        "    downsample_factor = pool_size ** 2\n",
        "    tiger_train = TextImageGenerator('./train/anpr_ocr/train/', img_w, img_h, batch_size, downsample_factor)\n",
        "    tiger_train.build_data()\n",
        "    tiger_val = TextImageGenerator('./val/anpr_ocr/train/', img_w, img_h, batch_size, downsample_factor)\n",
        "    tiger_val.build_data()\n",
        "\n",
        "    act = 'relu'\n",
        "    input_data = Input(name='the_input', shape=input_shape, dtype='float32')\n",
        "    inner = Conv2D(conv_filters, kernel_size, padding='same',\n",
        "                   activation=act, kernel_initializer='he_normal',\n",
        "                   name='conv1')(input_data)\n",
        "    inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max1')(inner)\n",
        "    inner = Conv2D(conv_filters, kernel_size, padding='same',\n",
        "                   activation=act, kernel_initializer='he_normal',\n",
        "                   name='conv2')(inner)\n",
        "    inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max2')(inner)\n",
        "\n",
        "    conv_to_rnn_dims = (img_w // (pool_size ** 2), (img_h // (pool_size ** 2)) * conv_filters)\n",
        "    inner = Reshape(target_shape=conv_to_rnn_dims, name='reshape')(inner)\n",
        "    inner = Dense(time_dense_size, activation=act, name='dense1')(inner)\n",
        "    inner = Dense(tiger_train.get_output_size(), kernel_initializer='he_normal',\n",
        "                name='dense2')(inner)\n",
        "    y_pred = Activation('softmax', name='softmax')(inner)\n",
        "    Model(inputs=input_data, outputs=y_pred).summary()\n",
        "\n",
        "    labels = Input(name='the_labels', shape=[tiger_train.max_text_len], dtype='float32')\n",
        "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
        "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
        "    \n",
        "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])   \n",
        "    sgd = SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n",
        "\n",
        "   \n",
        "    model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
        "\n",
        "  \n",
        "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd, metrics=['accuracy'])\n",
        "    \n",
        "   \n",
        "   \n",
        "\n",
        "    history = model.fit_generator(generator=tiger_train.next_batch(), \n",
        "                            steps_per_epoch=tiger_train.n,\n",
        "                            epochs=1,\n",
        "                            use_multiprocessing=True,\n",
        "                            validation_data=tiger_val.next_batch(), \n",
        "                            validation_steps=tiger_val.n)\n",
        "\n",
        "    return (model,history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M_bNKuP2gIi-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fLifimPkgIjB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model description and training"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "LheAMREsgIjD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model,history = train(load=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q2MXGsFfgIjI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Function to decode neural network output"
      ]
    },
    {
      "metadata": {
        "id": "8xprkHkUgIjK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def decode_batch(out):\n",
        "    ret = []\n",
        "    for j in range(out.shape[0]):\n",
        "        out_best = list(np.argmax(out[j, 2:], 1))\n",
        "        out_best = [k for k, g in itertools.groupby(out_best)]\n",
        "        outstr = ''\n",
        "        for c in out_best:\n",
        "            if c < len(letters):\n",
        "                outstr += letters[c]\n",
        "        ret.append(outstr)\n",
        "    return ret"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fYhN8bKCgIjO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Test on validation images"
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "s1s-3fiygIjP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tiger_test = TextImageGenerator('./test/anpr_ocr/test/', 128, 64, 8, 4)\n",
        "tiger_test.build_data()\n",
        "\n",
        "net_inp = model.get_layer(name='the_input').input\n",
        "net_out = model.get_layer(name='softmax').output\n",
        "\n",
        "for inp_value, _ in tiger_test.next_batch():\n",
        "    bs = inp_value['the_input'].shape[0]\n",
        "    X_data = inp_value['the_input']\n",
        "    net_out_value = sess.run(net_out, feed_dict={net_inp:X_data})\n",
        "    pred_texts = decode_batch(net_out_value)\n",
        "    labels = inp_value['the_labels']\n",
        "    texts = []\n",
        "    for label in labels:\n",
        "        text = ''.join(list(map(lambda x: letters[int(x)], label)))\n",
        "        texts.append(text)\n",
        "    \n",
        "    for i in range(bs):\n",
        "        fig = plt.figure(figsize=(10, 10))\n",
        "        outer = gridspec.GridSpec(2, 1, wspace=10, hspace=0.1)\n",
        "        ax1 = plt.Subplot(fig, outer[0])\n",
        "        fig.add_subplot(ax1)\n",
        "        ax2 = plt.Subplot(fig, outer[1])\n",
        "        fig.add_subplot(ax2)\n",
        "        print('Predicted: %s\\nTrue: %s' % (pred_texts[i], texts[i]))\n",
        "        img = X_data[i][:, :, 0].T\n",
        "        ax1.set_title('Input img')\n",
        "        ax1.imshow(img, cmap='gray')\n",
        "        ax1.set_xticks([])\n",
        "        ax1.set_yticks([])\n",
        "        ax2.set_title('Acrtivations')\n",
        "        ax2.imshow(net_out_value[i].T, cmap='binary', interpolation='nearest')\n",
        "        ax2.set_yticks(list(range(len(letters) + 1)))\n",
        "        ax2.set_yticklabels(letters + ['blank'])\n",
        "        ax2.grid(False)\n",
        "        for h in np.arange(-0.5, len(letters) + 1 + 0.5, 1):\n",
        "            ax2.axhline(h, linestyle='-', color='k', alpha=0.5, linewidth=1)\n",
        "        plt.show()\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d4ynL0htgIjU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"Testing : \")\n",
        "history_dict = history.history\n",
        "score = model.evaluate_generator(generator = tiger_test.next_batch(),steps = tiger_test.n)\n",
        "print(\"loss : \" +str(score[0]))\n",
        "print(\"acc : \" + str(score[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WS1XbHCIgIjb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loss_values = history_dict['loss']\n",
        "acc = history_dict['acc']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}